{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 0\n",
    "#Using thread to store the user input for task classification\n",
    "def background():\n",
    "    global inp\n",
    "    while True:\n",
    "        inp = int(input())\n",
    "\n",
    "def collectData():\n",
    "    return 0\n",
    "\n",
    "#Now threading1 runs regardless of user input\n",
    "threading1 = threading.Thread(target=background)\n",
    "threading1.daemon = True\n",
    "threading1.start()\n",
    "\n",
    "ser0 = serial.Serial('/dev/ttyACM0', 115200) # Establish the connection on a specific port\n",
    "ser1 = serial.Serial('/dev/ttyACM1', 115200) # Establish the connection on a specific port\n",
    "counter0 = 0 \n",
    "counter1 = 0 \n",
    "fhandle  = open(\"imu.txt\", 'ab')\n",
    "fhandle0 = open(\"imu0.txt\", 'ab')\n",
    "fhandle1 = open(\"imu1.txt\", 'ab')\n",
    "ihandle0 = open(\"intent0.txt\", 'ab')\n",
    "ihandle1 = open(\"intent1.txt\", 'ab')\n",
    "imu0    = []  #contains tstamps with imu0 data\n",
    "imu1    = []  #contains tstamps with imu1 data\n",
    "imu     = []\n",
    "\n",
    "intent0 = []\n",
    "intent1 = []\n",
    "ser0.flush()\n",
    "ser1.flush()\n",
    "start0 = time.time()\n",
    "start1 = time.time()\n",
    "t0     = time.time()\n",
    "t1     = time.time()\n",
    "\n",
    "#FFT might have the User Activity information as well i.e. running, walking, sitting etc. which can also be used for counterchecks for intent classification\n",
    "#Or the above info can be captured as well in the SVM classifier\n",
    "while True:\n",
    "    try:\n",
    "        counter0 +=1\n",
    "        counter1 +=1\n",
    "        #ser.write(str(chr(counter))) # Convert the decimal number to ASCII then send it to the Arduino\n",
    "        data0 = ser0.readline().rstrip()\n",
    "        data0 = data0.split()\n",
    "        data1 = ser1.readline().rstrip()\n",
    "        data1 = data1.split()\n",
    "        if ((len(data0) == 6) & (len(data1) == 6) & (inp<2)):\n",
    "            imu0.append([float(time.time()), int(data0[0]), int(data0[1]), int(data0[2]), int(data0[3]), int(data0[4]), int(data0[5])])\n",
    "            imu1.append([float(time.time()), int(data1[0]), int(data1[1]), int(data1[2]), int(data1[3]), int(data1[4]), int(data1[5])])\n",
    "            imu.append([float(time.time()),  (int(data0[0])*2.0)/ 32768.0, (int(data0[1])*2.0)/ 32768.0, (int(data0[2])*2.0)/ 32768.0, (int(data0[3])*250.0)/32768.0, (int(data0[4])*250.0)/32768.0, (int(data0[5])*250.0)/32768.0, (int(data1[0])*2.0)/ 32768.0, (int(data1[1])*2.0)/ 32768.0, (int(data1[2])*2.0)/ 32768.0, (int(data1[3])*250.0)/32768.0, (int(data1[4])*250.0)/32768.0, (int(data1[5])*250.0)/32768.0])\n",
    "            intent0.append(inp)\n",
    "            intent1.append(inp)\n",
    "        if counter0 == 255:\n",
    "            print(\"frequency:\", 255/(time.time()-t0))\n",
    "            t0 = time.time()\n",
    "            counter0 = 0\n",
    "        if counter1 == 255:\n",
    "            print(\"frequency:\", 255/(time.time()-t1))\n",
    "            t1 = time.time()\n",
    "            counter1 = 0\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        end=time.time()\n",
    "        d_time0=end-start0\n",
    "        d_time1=end-start1\n",
    "        np.savetxt(fhandle0, np.array(imu0),delimiter=\",\")\n",
    "        fhandle0.close()\n",
    "        np.savetxt(fhandle1, np.array(imu1),delimiter=\",\")\n",
    "        fhandle1.close()\n",
    "        np.savetxt(ihandle0, np.array(intent0),delimiter=\",\")\n",
    "        ihandle0.close()\n",
    "        np.savetxt(ihandle1, np.array(intent1),delimiter=\",\")\n",
    "        ihandle1.close()\n",
    "        np.savetxt(fhandle, np.array(imu),delimiter=\",\")\n",
    "        fhandle.close()\n",
    "        print(\"Avg Frequency is :: \", len(imu0)/d_time0)\n",
    "        print(\"Avg Frequency is :: \", len(imu1)/d_time1)\n",
    "        ser0.close()\n",
    "        ser1.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ser0 = serial.Serial('/dev/ttyACM0', 115200) # Establish the connection on a specific port 0\n",
    "#ser1 = serial.Serial('/dev/ttyACM1', 115200) # Establish the connection on a specific port 1\n",
    "#ser0.flush()\n",
    "#ser1.flush()\n",
    "\n",
    "intent_thres_imu = 10\n",
    "imu_data   = []\n",
    "pred_count = 0\n",
    "\n",
    "clf = joblib.load('weights/1s_6sps.pkl')\n",
    "print(clf)\n",
    "    \n",
    "print(\"Intention Probably is to pick up the bottle\")\n",
    "data_count = 0\n",
    "while(True):\n",
    "    try:\n",
    "        while(data_count<30):       #read data from imu\n",
    "            data0 = ser0.readline().rstrip()\n",
    "            data0 = data0.split()\n",
    "            data1 = ser1.readline().rstrip()\n",
    "            data1 = data1.split()\n",
    "            if (len(data0) == 6 & len(data1) == 6):\n",
    "                imu_data.append([float(time.time()),  int(data0[0]), int(data0[1]), int(data0[2]), int(data0[3]), int(data0[4]), int(data0[5]), int(data1[0]), int(data1[1]), int(data1[2]), int(data1[3]), int(data1[4]), int(data1[5])])\n",
    "                data_count = data_count + 1\n",
    "                \n",
    "        data_count = 0\n",
    "        bucket    = get_buckets(np.array(imu_data[-30:]), 1, 30, 40)   #send the last 30 elements data to get_samples function\n",
    "        predicted = clf.predict(np.reshape(bucket, (1, 40)))           #reshaping and sending for classification\n",
    "        print(bucket)\n",
    "        if(predicted == 1):\n",
    "            pred_count = pred_count + 1\n",
    "            print(\"IMU intent Prediction Count\", pred_count)\n",
    "            if(pred_count>intent_thres_imu):\n",
    "                print(\"Intended Action is XYZ\")\n",
    "            else:\n",
    "                print(\"IMU intent Prediction Count\", pred_count)\n",
    "                pred_count = pred_count - 1\n",
    "    except KeyboardInterrupt:\n",
    "        ser0.flush()\n",
    "        ser0.close()\n",
    "        ser1.flush()\n",
    "        ser1.close()\n",
    "        pass\n",
    "        #keep a counter for it as well\n",
    "        #wait for threshold to predict the intection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = threading.Thread(target=getRefInput)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "inp = '3'\n",
    "\n",
    "file, flist = createFile('data/11testfile.h5')\n",
    "\n",
    "imu_num = 2\n",
    "imu_data_chunk = 100\n",
    "imu_data  = deque([deque([]) for _ in range(imu_num)])\n",
    "tstamp    = deque([deque([]) for _ in range(imu_num)])\n",
    "\n",
    "#Open serial port for reading data from Intel Curie IMU\n",
    "ser0 = serial.Serial('/dev/ttyACM0', 115200) # Establish the connection on a specific port 0\n",
    "ser1 = serial.Serial('/dev/ttyACM1', 115200) # Establish the connection on a specific port 1\n",
    "ser0.flush()\n",
    "ser1.flush()\n",
    " \n",
    "while inp!='s':  #as of now continous loop but should be more adaptive and intuitive #take care of 'garbage data'\n",
    "    data0 = ser0.readline().rstrip()\n",
    "    data0 = data0.split()\n",
    "    data1 = ser1.readline().rstrip()\n",
    "    data1 = data1.split()\n",
    "    if (len(data0) == 6 & len(data1) == 6):\n",
    "        tstamp[connection].append(time.time()) \n",
    "        imu_data.append([int(data0[0]), int(data0[1]), int(data0[2]), int(data0[3]), int(data0[4]), int(data0[5]), 0, 0, 0, int(data1[0]), int(data1[1]), int(data1[2]), int(data1[3]), int(data1[4]), int(data1[5]), 0, 0, 0])\n",
    "        #imu_data[connection].append(value_data[2::2])     #storing all 9-axis imu data\n",
    "\n",
    "        if((len(imu_data[connection]) == imu_data_chunk) or (inp == 's')):\n",
    "            saveData(flist, connection, imu_data, tstamp)\n",
    "            print(\"Average Sampling Freq. of\", imu_data_chunk, \"elements is ::\", getFreq(tstamp, connection, show=False))     #imu_data_chunk/(tstamp[connection][0]-tstamp[connection][299])\n",
    "            imu_data[connection].clear()\n",
    "            tstamp[connection].clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies(data, timestamps):\n",
    "    num_seconds = float(timestamps[-2] - timestamps[0])\n",
    "    samples_per_second = len(data) / num_seconds\n",
    "    num_samples = len(data)\n",
    "    oscilations_per_sample = [float(oscilations) / num_samples for oscilations in range(0, num_samples)]\n",
    "    return [ops * samples_per_second for ops in oscilations_per_sample]\n",
    "\n",
    "def get_buckets(data, first, last, num_buckets, hertz_cutoff=float(5)):\n",
    "    # Transform all of the original data to be a single component along the first principal component\n",
    "    pca = PCA(n_components=1, copy=True, whiten=True)\n",
    "    transformed_dataset = PCA.fit_transform(pca, data)\n",
    "    #print(pca.explained_variance_ratio_)\n",
    "    slice=transformed_dataset[first:last]\n",
    "\n",
    "    transformed = fft.fft(slice)\n",
    "    absolute = [abs(complex) for complex in transformed]\n",
    "\n",
    "    frequencies = get_frequencies(data, (data.T)[0])\n",
    "\n",
    "    buckets = [0 for i in range(num_buckets)]\n",
    "    width = hertz_cutoff / num_buckets\n",
    "    sum_of_buckets = 0.0000001\n",
    "    for i in range(1, len(absolute)):\n",
    "        index = int(frequencies[i] / width)\n",
    "        if index >= num_buckets:\n",
    "            break;\n",
    "        buckets[index] += absolute[i]\n",
    "        sum_of_buckets += absolute[i]\n",
    "\n",
    "    if 0: #arguments['--normalize']:\n",
    "        buckets = map(lambda x: x/sum_of_buckets, buckets)\n",
    "\n",
    "    return buckets\n",
    "\n",
    "def get_samples(data, target):\n",
    "    result = []\n",
    "    intent = []\n",
    "    segmentsize=30\n",
    "    stride=5            # Reduce this to very little to get very large trainingsets\n",
    "    noOfBuckets=40\n",
    "    clas = np.array(target)\n",
    "    for  start in range(0, len(data) - segmentsize, stride):\n",
    "        if ((sum(clas[start: start + stride])<stride) & (sum(clas[start: start + stride])>0)): #((clas[start: start + stride]==).all()):\n",
    "            continue\n",
    "        if start + segmentsize <= len(data):\n",
    "            segments_buckets = get_buckets(data, start, start + segmentsize, noOfBuckets)\n",
    "            #print(segments_buckets)\n",
    "            intent.append(clas[start])\n",
    "            result.append(segments_buckets)\n",
    "    return result, intent\n",
    "\n",
    "def getPCASample(data, target, isPCA=True):\n",
    "    result = []\n",
    "    intent = []\n",
    "    segmentsize=30\n",
    "    stride=2            # Reduce this to very little to get very large trainingsets\n",
    "    noOfBuckets=40\n",
    "    clas = np.array(target)\n",
    "    pca = PCA(n_components=1, copy=True, whiten=True)\n",
    "    \n",
    "    #Pre-processing the data\n",
    "    arr = np.array(data).T\n",
    "    new_arr = arr[1:13]\n",
    "    new_arr[0]  = (new_arr[0]*2)/ 32768.0\n",
    "    new_arr[1]  = (new_arr[1]*2)/ 32768.0\n",
    "    new_arr[2]  = (new_arr[2]*2)/ 32768.0\n",
    "    new_arr[3]  = (new_arr[3]*250)/ 32768.0\n",
    "    new_arr[4]  = (new_arr[4]*250)/ 32768.0\n",
    "    new_arr[5]  = (new_arr[5]*250)/ 32768.0\n",
    "    new_arr[6]  = (new_arr[6]*2)/ 32768.0\n",
    "    new_arr[7]  = (new_arr[7]*2)/ 32768.0\n",
    "    new_arr[8]  = (new_arr[8]*2)/ 32768.0\n",
    "    new_arr[9]  = (new_arr[9]*250)/ 32768.0\n",
    "    new_arr[10] = (new_arr[10]*250)/ 32768.0\n",
    "    new_arr[11] = (new_arr[11]*250)/ 32768.0\n",
    "    \n",
    "    new_arr = new_arr.T\n",
    "    \n",
    "    if isPCA:\n",
    "        transformed_dataset = PCA.fit_transform(pca, new_arr)\n",
    "    else:\n",
    "        transformed_dataset = new_arr\n",
    "    #transformed_dataset = PCA.fit_transform(pca, data)\n",
    "    \n",
    "    for  start in range(0, len(data) - segmentsize, stride):\n",
    "        if ((sum(clas[start: start + stride])<stride) & (sum(clas[start: start + stride])>0)): #((clas[start: start + stride]==).all()):\n",
    "            continue\n",
    "        if start + segmentsize <= len(data):\n",
    "            intent.append(clas[start])\n",
    "            result.append(np.reshape(transformed_dataset[start:start+segmentsize], (30,)))\n",
    "    return result, intent\n",
    "\n",
    "def plotDataset(start, end):\n",
    "    imu_data = loadData(\"data/imu.txt\").T\n",
    "    intent   = loadData(\"data/intent0.txt\")\n",
    "    abs_data = np.abs(imu_data)\n",
    "    for i in range(6):\n",
    "        data = abs_data[i+1]\n",
    "        pdata= data[start:end]\n",
    "        plt.plot((pdata-min(pdata))/(max(pdata)-min(pdata)))\n",
    "        plt.plot(intent[start:end])\n",
    "        plt.show()\n",
    "        \n",
    "    return imu_data, intent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
